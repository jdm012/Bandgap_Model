{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731898a5",
   "metadata": {},
   "source": [
    "# Analysis of Feature Abstractions from Deep Learning Models  \n",
    "\n",
    "This notebook investigates the feature abstractions captured in the penultimate layer of predictive deep learning models.  \n",
    "By examining these intermediate representations, we explore how the models transform raw inputs into higher-level abstractions that ultimately support bandgap prediction.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f94901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210a2544",
   "metadata": {},
   "source": [
    "Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9694816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DL trained model\n",
    "modelo = tf.keras.models.load_model('Best_Models/July_21_211501_2024_0.019fgsm_0.0001lr_1200_0.0_32_4_hidden_600__b/July_21_211501_2024_0.019fgsm_0.0001lr_1200_0.0_32_4_hidden_600.keras')\n",
    "modelo.trainable = False\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3925a19e",
   "metadata": {},
   "source": [
    "The model is cut off just before the output layer, retaining activations from the penultimate layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb1ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCropped = tf.keras.models.Model(inputs = modelo.inputs, outputs = modelo.get_layer('add_1').output, name = 'Add')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe96fd",
   "metadata": {},
   "source": [
    "Test set features and target variables are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34556b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = np.load('data/patolli_generated_data/patolli_xtest.npy')\n",
    "ytest= np.load('data/patolli_generated_data/patolli_ytest.npy')\n",
    "print(xtest.shape,ytest.shape)\n",
    "Add_layer_output = modelCropped.predict(xtest[:,0,:], batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84db2efc",
   "metadata": {},
   "source": [
    "Feature Abstraction Analysis from the Penultimate Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa5722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pca_analysis_and_plot(data, n_components=10):\n",
    "    \"\"\"\n",
    "    Applies PCA to the data, prints explained variance ratios, and plots the principal components.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: The input data for PCA.\n",
    "    - n_components: The number of principal components to keep.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=n_components)  # Reduce to n_components dimensions\n",
    "    X_pca = pca.fit_transform(data)\n",
    "\n",
    "    print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "    print(\"Cumulative explained variance:\", np.cumsum(pca.explained_variance_ratio_))\n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(i + 1, 4):  # Ensure j > i to avoid repetition\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.scatter(X_pca[:, i], X_pca[:, j])\n",
    "            plt.xlabel(f'Principal Component {i+1}')\n",
    "            plt.ylabel(f'Principal Component {j+1}')\n",
    "            plt.title(f'PC{i+1} vs PC{j+1}')\n",
    "            plt.show()\n",
    "    return X_pca\n",
    "\n",
    "x_pca=pca_analysis_and_plot(Add_layer_output, n_components=120)\n",
    "print(x_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc755f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_elbow_method(data, max_clusters=20):\n",
    "    \"\"\"\n",
    "    Plots the Elbow Method graph to determine the optimal number of clusters.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: The input data for KMeans clustering.\n",
    "    - max_clusters: The maximum number of clusters to test. Default is 20.\n",
    "    \"\"\"\n",
    "    wcss = []\n",
    "    for i in range(1, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=i, random_state=0)\n",
    "        kmeans.fit(data)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, max_clusters + 1), wcss, marker='o')\n",
    "    plt.title('Elbow Method')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.xticks(np.arange(0, max_clusters+1, step=1))\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "plot_elbow_method(x_pca, max_clusters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790d4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def plot_silhouette_scores(data, min_clusters=2, max_clusters=20):\n",
    "    \"\"\"\n",
    "    Plots the silhouette scores for different numbers of clusters to determine the optimal number of clusters.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: The input data for KMeans clustering.\n",
    "    - min_clusters: The minimum number of clusters to test. Default is 2.\n",
    "    - max_clusters: The maximum number of clusters to test. Default is 20.\n",
    "    \"\"\"\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    for i in range(min_clusters, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=i, random_state=0)\n",
    "        kmeans.fit(data)\n",
    "        score = silhouette_score(data, kmeans.labels_)\n",
    "        silhouette_scores.append(score)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(min_clusters, max_clusters + 1), silhouette_scores, marker='o')\n",
    "    plt.title('Silhouette Score')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.xticks(np.arange(0, max_clusters+1, step=1))\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "plot_silhouette_scores(x_pca, min_clusters=2, max_clusters=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac625aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gap_statistic(X, k_max, B=10):\n",
    "    gaps = []\n",
    "    ks = range(1, k_max + 1)\n",
    "    \n",
    "    # Compute WCSS for original data\n",
    "    wcss = []\n",
    "    for k in ks:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0).fit(X)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    \n",
    "    # Generate reference datasets and compute WCSS\n",
    "    ref_wcss = np.zeros((B, k_max))\n",
    "    for i in range(B):\n",
    "        ref_data = np.random.random_sample(size=X.shape)\n",
    "        for k in ks:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42).fit(ref_data)\n",
    "            ref_wcss[i, k-1] = kmeans.inertia_\n",
    "    \n",
    "    # Compute the Gap Statistic\n",
    "    log_wcss_ref = np.log(ref_wcss)\n",
    "    log_wcss = np.log(np.array(wcss))\n",
    "    gap = np.mean(log_wcss_ref, axis=0) - log_wcss\n",
    "    \n",
    "    return gap, ks\n",
    "\n",
    "max_clusters = 30\n",
    "gap, ks = compute_gap_statistic(x_pca, max_clusters)\n",
    "\n",
    "# Plot \n",
    "plt.plot(ks, gap, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Gap Statistic')\n",
    "plt.title('Gap Statistic vs. Number of Clusters')\n",
    "plt.xticks(np.arange(0, max_clusters+1, step=1))\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52370a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kmeans_clustering(x,y,n_clusters=3):\n",
    "\n",
    "    # Add the cluster labels to the reduced data\n",
    "    reduced_data = pd.DataFrame(x, columns=[f'PC{i+1}' for i in range(x.shape[-1])])\n",
    "    kmeans = KMeans(n_clusters=n_clusters,init='k-means++',tol=0.001, random_state=0,verbose=0)\n",
    "    kmeans.fit_predict(reduced_data)\n",
    "    kmeans_labels =kmeans.labels_\n",
    "    reduced_data['Cluster'] = kmeans_labels\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    for cluster in np.unique(kmeans_labels):\n",
    "        cluster_data = reduced_data[reduced_data['Cluster'] == cluster]\n",
    "\n",
    "        plt.scatter(cluster_data['PC1'], cluster_data['PC2'], label=f'Cluster {cluster}')\n",
    "    plt.title('KMeans Clustering')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return None\n",
    "\n",
    "Kmeans_clustering(x_pca,ytest,7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af240c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minisom import MiniSom\n",
    "def train_and_plot_som(data, x_size=3, y_size=2, input_len=1200, sigma=0.5, learning_rate=0.001, \n",
    "                       random_seed=0, num_iterations=1000):\n",
    "    \"\"\"\n",
    "    Trains a Self-Organizing Map (SOM) and plots the resulting clusters and centroids.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: The input data for SOM training.\n",
    "    - x_size: Number of neurons in the x-direction of the SOM grid. Default is 3.\n",
    "    - y_size: Number of neurons in the y-direction of the SOM grid. Default is 2.\n",
    "    - input_len: Length of the input vector. Default is 1200.\n",
    "    - sigma: Spread of the Gaussian function. Default is 0.5.\n",
    "    - learning_rate: Learning rate of the SOM. Default is 0.001.\n",
    "    - random_seed: Seed for random number generation. Default is 0.\n",
    "    - num_iterations: Number of iterations for training. Default is 10009.\n",
    "    \"\"\"\n",
    "    # Initialize and train the SOM\n",
    "    som = MiniSom(x_size, y_size, input_len, sigma=sigma, learning_rate=learning_rate, random_seed=random_seed)\n",
    "    som.random_weights_init(data)\n",
    "    som.train_random(data, num_iterations, verbose=True)\n",
    "    \n",
    "    # Compute the winner coordinates\n",
    "    winner_coordinates = np.array([som.winner(x) for x in data]).T\n",
    "    cluster_index = np.ravel_multi_index(winner_coordinates, (x_size, y_size))\n",
    "    \n",
    "    # Plotting the clusters\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    for c in np.unique(cluster_index):\n",
    "        plt.scatter(data[cluster_index == c, 0], data[cluster_index == c, 1], \n",
    "                    label=f'Cluster {c}')\n",
    "    \n",
    "    # Plotting centroids\n",
    "    for centroid in som.get_weights():\n",
    "        plt.scatter(centroid[:, 0], centroid[:, 1], marker='x', \n",
    "                    s=100, linewidths=3, color='k', label='Centroid')\n",
    "    \n",
    "    plt.title('SOM Clusters and Centroids')\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "    plt.legend()\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "train_and_plot_som(x_pca, x_size=2, y_size=2, input_len=x_pca.shape[-1], sigma=0.05, \n",
    "                  learning_rate=0.1, random_seed=0, num_iterations=10000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
